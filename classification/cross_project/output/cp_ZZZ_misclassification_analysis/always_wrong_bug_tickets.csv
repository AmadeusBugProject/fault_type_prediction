,doc,url,correct,target,prediction,count
300,"Strange behavior with february when calculate period and espessially the month calculation
about the february month there is a strange behavior that you can see in the incorect results with jodatime, you can look down here : 

```
        DateTime date4 = new DateTime(2013, 5, 29, 0, 0, 0, 0);
        DateTime date4PlusNineMonths = new DateTime(2014, 2, 28, 0, 0, 0, 0);
        Period period4 = new Period(date4, date4PlusNineMonths);
        //Incorrect result
        System.out.print(date4.toString(""dd/MM/YYYY"")+"".plusMonths(9) = ""+ date4.plusMonths(9).toString(""dd/MM/YYYY""));
        System.out.print(period4.getYears() +""Years/""+ period4.getMonths() +""Months/""+ period4.getWeeks() +""Weeks/""+ period4.getDays() +""Days"");
```

Output :
    29/05/2013.plusMonths(9) = 28/02/2014 //incorrect result should be 01/03/2014
    0Years/9Months/0Weeks/0Days

This is an incorrect calculation It should be 0Years/8Months/4Weeks/2Days Isn't it...?

If it is correct so why when I increase two days more (30 and 31) it always give me the same calculation (0Years/9Months/0Weeks/0Days) we all agree that days are really decreasing or am I dreaming...?

Now maybe I wrong in my use of the joda framework because in the app I develop I do a check everyday on a period to have the precise month separation between two date (toDay and the next date) and if I have 9months and 1day it's too late I need to have 9months and 0days as required in my app =/

If I wrong how can I achieve this please...?
",https://github.com/JodaOrg/joda-time/issues/31,0.0,2.0,2.0357142857142856,56
38,"Cannot suppress output of ""Lost connection to the server....""
<!--
Hi there! thank you for discovering and submitting an issue!

Please first tell us a little bit about the environment you're running:
The commands in the comments can be run directly in a command prompt.
-->


- **OS and version used:** Windows 10 

- **Java runtime used:** <VERSION> Java 8

- **SDK version used:** <VERSION> 1.7.0


# Description of the issue:
Printout of ""Lost connection to the server."" is printed both to System.out and to log.
This makes it harder/impossible to suppres that output that would go to log with info level.

I found the message in 
https://github.com/Azure/azure-iot-sdk-java/blob/master/device/iot-device-client/src/main/java/com/microsoft/azure/sdk/iot/device/transport/amqps/AmqpsIotHubConnection.java#L769

---
System.out.println(""Lost connection to the server. Reconnection attempt "" + currentReconnectionAttempt++ + ""..."");
        logger.LogInfo(""Lost connection to the server. Reconnection attempt %s, method name is %s "", currentReconnectionAttempt, logger.getMethodName());
---

My suggestion is to remove the System.out line 

",https://github.com/Azure/azure-iot-sdk-java/issues/205,0.0,3.0,0.42857142857142855,14
293,"Slider not showing in simulator iOs skins
Original [issue 1161](https://code.google.com/p/codenameone/issues/detail?id=1161) created by codenameone on 2014-07-30T14:31:42.000Z:

The slider is not showing in the simulator on iOs skins. Other skins are showing the slider.

<b>What steps will reproduce the problem?</b>
1. Add a slider to the main form
2. Run in simulator in an iOs skin

<b>What is the expected output? What do you see instead?</b>

The expected output is a slider on the screen. I see nothing. When I set 'setRenderValueOnTop' to true and I slide to left and right on the place the slider should be, I can see the number going up and down. So there is a slider, but it's not visible.

<b>What version of the product are you using? On what operating system?</b>

Netbeans 8, Java 1.8, Linux, CodenameOne plugin: latest (I can't find the version in Netbeans, last check was today and there is no newer version).

<b>Please provide any additional information below.</b>

In all other platforms (simulated), there is a slider showing. I didn't test on real devices.
",https://github.com/codenameone/CodenameOne/issues/1160,0.0,2.0,1.7142857142857142,28
313,"ThrottleRequestFilter swallows interfaces
The ThrottleRequestFilter wraps the AsyncHandler with an AsyncHandlerWrapper. This way all additional interfaces implemented by the originating AsyncHandler get lost. E.g. ProgressAsyncHandler, ResumableAsyncHandler or any custom interfaces.

Suggestion: Maybe use a dynamic proxy which implements all interfaces of the originating AsyncHandler instead of using AsyncHandlerWrapper.
",https://github.com/AsyncHttpClient/async-http-client/issues/1314,0.0,0.0,2.674107142857143,224
316,"Tomcat 7.0.50 shutdown issue
After updating HikariCP from 1.2.8 to 1.3.0 during shutdown Apache Tomcat 7.0.50 I'm getting these messages in catalina.log:

Mar 02, 2014 5:27:40 PM org.apache.catalina.core.StandardServer await
INFO: A valid shutdown command was received via the shutdown port. Stopping the Server instance.
Mar 02, 2014 5:27:40 PM org.apache.coyote.AbstractProtocol pause
INFO: Pausing ProtocolHandler [""http-apr-8080""]
Mar 02, 2014 5:27:40 PM org.apache.coyote.AbstractProtocol pause
INFO: Pausing ProtocolHandler [""ajp-apr-8009""]
Mar 02, 2014 5:27:40 PM org.apache.catalina.core.StandardService stopInternal
INFO: Stopping service Catalina
Mar 02, 2014 5:27:40 PM org.apache.catalina.core.ApplicationContext log
INFO: Closing Spring root WebApplicationContext
Mar 02, 2014 5:27:40 PM org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks
SEVERE: The web application [/test] created a ThreadLocal with key of type [com.zaxxer.hikari.util.ConcurrentBag$1](value [com.zaxxer.hikari.util.ConcurrentBag$1@1b6f3995]) and a value of type [java.util.LinkedList](value [[com.zaxxer.hikari.proxy.ConnectionJavassistProxy@af5dd35]]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.
Mar 02, 2014 5:27:40 PM org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks
SEVERE: The web application [/test] created a ThreadLocal with key of type [com.zaxxer.hikari.util.ConcurrentBag$1](value [com.zaxxer.hikari.util.ConcurrentBag$1@1b6f3995]) and a value of type [java.util.LinkedList](value [[com.zaxxer.hikari.proxy.ConnectionJavassistProxy@4034afa3]]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.
Mar 02, 2014 5:27:40 PM org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks
SEVERE: The web application [/test] created a ThreadLocal with key of type [com.zaxxer.hikari.util.ConcurrentBag$1](value [com.zaxxer.hikari.util.ConcurrentBag$1@1b6f3995]) and a value of type [java.util.LinkedList](value [[com.zaxxer.hikari.proxy.ConnectionJavassistProxy@4034afa3]]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.
Mar 02, 2014 5:27:40 PM org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks
SEVERE: The web application [/test] created a ThreadLocal with key of type [com.zaxxer.hikari.util.ConcurrentBag$1](value [com.zaxxer.hikari.util.ConcurrentBag$1@1b6f3995]) and a value of type [java.util.LinkedList](value [[com.zaxxer.hikari.proxy.ConnectionJavassistProxy@af5dd35]]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.
Mar 02, 2014 5:27:40 PM org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks
SEVERE: The web application [/test] created a ThreadLocal with key of type [com.zaxxer.hikari.util.ConcurrentBag$1](value [com.zaxxer.hikari.util.ConcurrentBag$1@1b6f3995]) and a value of type [java.util.LinkedList](value [[com.zaxxer.hikari.proxy.ConnectionJavassistProxy@af5dd35]]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.
Mar 02, 2014 5:27:40 PM org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks
SEVERE: The web application [/test] created a ThreadLocal with key of type [com.zaxxer.hikari.util.ConcurrentBag$1](value [com.zaxxer.hikari.util.ConcurrentBag$1@1b6f3995]) and a value of type [java.util.LinkedList](value [[com.zaxxer.hikari.proxy.ConnectionJavassistProxy@af5dd35]]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.
Mar 02, 2014 5:27:40 PM org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks
SEVERE: The web application [/test] created a ThreadLocal with key of type [com.zaxxer.hikari.util.ConcurrentBag$1](value [com.zaxxer.hikari.util.ConcurrentBag$1@1b6f3995]) and a value of type [java.util.LinkedList](value [[com.zaxxer.hikari.proxy.ConnectionJavassistProxy@4034afa3]]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.
Mar 02, 2014 5:27:40 PM org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks
SEVERE: The web application [/test] created a ThreadLocal with key of type [com.zaxxer.hikari.util.ConcurrentBag$1](value [com.zaxxer.hikari.util.ConcurrentBag$1@1b6f3995]) and a value of type [java.util.LinkedList](value [[com.zaxxer.hikari.proxy.ConnectionJavassistProxy@4034afa3]]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.
Mar 02, 2014 5:27:40 PM org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks
SEVERE: The web application [/test] created a ThreadLocal with key of type [com.zaxxer.hikari.util.ConcurrentBag$1](value [com.zaxxer.hikari.util.ConcurrentBag$1@1b6f3995]) and a value of type [java.util.LinkedList](value [[com.zaxxer.hikari.proxy.ConnectionJavassistProxy@af5dd35]]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.
Mar 02, 2014 5:27:40 PM org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks
SEVERE: The web application [/test] created a ThreadLocal with key of type [com.zaxxer.hikari.util.ConcurrentBag$1](value [com.zaxxer.hikari.util.ConcurrentBag$1@1b6f3995]) and a value of type [java.util.LinkedList](value [[com.zaxxer.hikari.proxy.ConnectionJavassistProxy@af5dd35]]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.
Mar 02, 2014 5:27:40 PM org.apache.coyote.AbstractProtocol stop
INFO: Stopping ProtocolHandler [""http-apr-8080""]
Mar 02, 2014 5:27:40 PM org.apache.coyote.AbstractProtocol stop
INFO: Stopping ProtocolHandler [""ajp-apr-8009""]
Mar 02, 2014 5:27:40 PM org.apache.coyote.AbstractProtocol destroy
INFO: Destroying ProtocolHandler [""http-apr-8080""]
Mar 02, 2014 5:27:40 PM org.apache.coyote.AbstractProtocol destroy
INFO: Destroying ProtocolHandler [""ajp-apr-8009""]
",https://github.com/brettwooldridge/HikariCP/issues/39,0.0,3.0,1.0,119
31,"Can't change html when using ""spring-boot-starter-mustache"" with Eclipse.
I want to use SpringBoot, SpringDevtool, Mustache, Gradle, and Eclipse on Windows10.
But not work.
1. I run as ""Spring Boot app"" at Eclipse, and Tomcat start.
2. I can change html in ""src/main/templates""
3. I access ""localhost:8080"" by chrome browser.
4. I change html, then Eclipse error `The project was not built due to ""Could not delete '/${projectname}/bin/templates'."". Fix the problem, then try refreshing this project and building it since it may be inconsistent` occurred, so ""localhost:8080"" return error.

Are SpringBoot and Mustache and Eclipse bad combination?

My build.gradle is ...

```
apply plugin: 'java'
apply plugin: 'eclipse'
apply plugin: 'spring-boot' 

sourceCompatibility = '1.8'
targetCompatibility = '1.8'

repositories {
    mavenCentral()
}

buildscript {
    repositories {
        mavenCentral()
    }
    dependencies {
        classpath(""org.springframework.boot:spring-boot-gradle-plugin:1.3.1.RELEASE"")
    }
}

dependencies {
    compile 'org.springframework.boot:spring-boot-starter-web:1.3.1.RELEASE'
    compile 'org.springframework.boot:spring-boot-starter-mustache:1.3.1.RELEASE'
}
```
",https://github.com/spring-projects/spring-boot/issues/4921,0.0,1.0,2.0,91
253,"Randomly failing test case in class InstallUninstallNPMPluginUITest
Test `testInstallNpmsThenUninstallOneDependency` in class `InstallUninstallNPMPluginUITest` fails randomly with the following exception:

```
IResourceDescription in index must not be an instance of ResourceDescriptionWithoutModuleUserData but it was. URI: file:/var/lib/build/workspace/n4js-extended-nightly/n4js-n4/tests/com.enfore.n4js.ui.tests/target/work/data/.metadata/.plugins/org.eclipse.n4js.external.libraries/.n4npm/node_modules/lodash/fp/matches.js
IResourceDescription in index must not be an instance of ResourceDescriptionWithoutModuleUserData but it was. URI: file:/var/lib/build/workspace/n4js-extended-nightly/n4js-n4/tests/com.enfore.n4js.ui.tests/target/work/data/.metadata/.plugins/org.eclipse.n4js.external.libraries/.n4npm/node_modules/lodash/bind.js
[...]
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.eclipse.n4js.tests.builder.AbstractBuilderTest.assertXtextIndexIsValid(AbstractBuilderTest.java:274)
	at org.eclipse.n4js.tests.builder.AbstractBuilderTest.waitForAutoBuild(AbstractBuilderTest.java:204)
	at org.eclipse.n4js.tests.builder.AbstractBuilderTest.waitForAutoBuild(AbstractBuilderTest.java:197)
	at com.enfore.n4js.tests.externalPackages.InstallUninstallNPMPluginUITest.testInstallNpmsThenUninstallOneDependency(InstallUninstallNPMPluginUITest.java:184)
```

For sample builds showing this failure see internal Jenkins build server.
  ",https://github.com/eclipse/n4js/issues/444,0.0,0.0,2.0,154
242,"Prepared params, IN clause, array of enums: stackoverflow exception
### OrientDB Version: 2.2.20 

`SELECT * FROM Project WHERE status in :status`

if status is enum array (tested with 2 elements), it will fall into infinite recursion during parsing named parameters, and end in stackoverflow.

This one works, if :status is Enum:
`SELECT * FROM Project WHERE status = :status`


```
// toParsedTree function
 ...
      while (iterator.hasNext()) {
        Object o = iterator.next();
        OExpression exp = new OExpression(-1);
        exp.value = toParsedTree(o); //recursive call, returns itself, one time for each element in array
        coll.expressions.add(exp);
      }
...
```

Not particulary painfull, as I can map Enum to String on my own, but confusing, since status = :status, where status is enum works.

Part of stack: 

> ERROR [2017-05-15 09:54:47,472] io.dropwizard.jersey.errors.LoggingExceptionMapper: Error handling a request: f8918bc72cb46f84
> ! java.lang.StackOverflowError: null
> ! at com.orientechnologies.common.collection.OMultiValue.isMultiValue(OMultiValue.java:50)
> ! at com.orientechnologies.common.collection.OMultiValue.isMultiValue(OMultiValue.java:62)
> ! at com.orientechnologies.orient.core.sql.parser.OInputParameter.toParsedTree(OInputParameter.java:77)
> ! at com.orientechnologies.orient.core.sql.parser.ONamedParameter.bindFromInputParams(ONamedParameter.java:49)
> ! at com.orientechnologies.orient.core.sql.parser.ONamedParameter.toString(ONamedParameter.java:31)
> ! at com.orientechnologies.orient.core.sql.parser.OExpression.toString(OExpression.java:104)
> ! at com.orientechnologies.orient.core.sql.parser.OCollection.toString(OCollection.java:35)
> ! at com.orientechnologies.orient.core.sql.parser.ONamedParameter.toString(ONamedParameter.java:39)
> ! at com.orientechnologies.orient.core.sql.parser.OExpression.toString(OExpression.java:104)
> ! at com.orientechnologies.orient.core.sql.parser.OCollection.toString(OCollection.java:35)
> ! at com.orientechnologies.orient.core.sql.parser.ONamedParameter.toString(ONamedParameter.java:39)
> ! at com.orientechnologies.orient.core.sql.parser.OExpression.toString(OExpression.java:104)
> ! at com.orientechnologies.orient.core.sql.parser.OCollection.toString(OCollection.java:35)
> ! at com.orientechnologies.orient.core.sql.parser.ONamedParameter.toString(ONamedParameter.java:39)
> ! at com.orientechnologies.orient.core.sql.parser.OExpression.toString(OExpression.java:104)
> ! at com.orientechnologies.orient.core.sql.parser.OCollection.toString(OCollection.java:35)
>  ...",https://github.com/orientechnologies/orientdb/issues/7418,0.0,1.0,3.0,49
228,"Parsing a date string with an incorrect day of the week does not throw any errors
If you parse a string that has an incorrect day of the week , e.g.

``` java
// July 14, 2012 is a Saturday, but let's call it a Friday
DateTimeFormat.forPattern(""EEE MMM dd yyyy"").parseDateTime(""Fri Jul 14 2012"");
```

No parse errors are thrown, but it changes the date to be the 13th, rather than the 14th as in the string to be parsed.
",https://github.com/JodaOrg/joda-time/issues/78,0.0,2.0,3.0,56
295,"Spring Boot - Maven Plugin shutdown broken
As of 2.2.0 the shutdown of a spring-boot application is broken and results in a Build Failure when executed.

I ran ```mvnw clean install package spring-boot:run``` as a command.

In attachment the executable file of a boot from https://start.spring.io/ and the resulted build fail. I ran with Java 8, and the Maven wrapper included in the project. 

[output.txt](https://github.com/spring-projects/spring-boot/files/3822172/output.txt)
",https://github.com/spring-projects/spring-boot/issues/18936,0.0,0.0,2.0,91
220,"ODB server doesn't totally respect the ""storage.diskCache.pageSize"" directive
according to the default value of the ""storage.diskCache.pageSize"" directive (64k), during an ""import database"" test I observed these write bytes size distribution:

```
     value  ------------- Distribution ------------- count
           0 |                                         0
           1 |@@@@@@@@@@@@@@@@@@@@@@@@@                8811
           2 |                                         0
           4 |                                         0
           8 |@                                        407
          16 |                                         77
          32 |@                                        182
          64 |                                         6
         128 |                                         0
         256 |                                         13
         512 |                                         12
        1024 |                                         26
        2048 |                                         47
        4096 |                                         35
        8192 |                                         0
       16384 |                                         0
       32768 |                                         0
       65536 |@@@@@@@@@@@@                             4363
      131072 |                                         0
```

It means that there were 8811 writes of 1 byte and 4363 writes of 65536 bytes (as expected), and so on.

After setting the ""storage.diskCache.pageSize"" value to ""32"", I observed these details  for the same process:

 zfs pwrite /zones/orientdbZone/root/opt/orientdb-community-1.6.4/databases

```
       value  ------------- Distribution ------------- count
           0 |                                         0
           1 |@@@@@                                    275
           2 |                                         0
           4 |                                         0
           8 |@@@@@@@                                  399
          16 |                                         0
          32 |                                         0
          64 |                                         0
         128 |                                         0
         256 |                                         13
         512 |                                         12
        1024 |                                         26
        2048 |@                                        47
        4096 |@                                        35
        8192 |                                         0
       16384 |                                         0
       32768 |@@@@@@@@@@@@@@@@@@@@@@@@@@@              1604
       65536 |                                         0
```

 zfs write /zones/orientdbZone/root/opt/orientdb-community-1.6.4/databases

```
       value  ------------- Distribution ------------- count
           0 |                                         0
           1 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@        8536
           2 |                                         0
           4 |                                         0
           8 |                                         8
          16 |                                         77
          32 |@                                        182
          64 |                                         6
         128 |                                         0
         256 |                                         0
         512 |                                         0
        1024 |                                         0
        2048 |                                         0
        4096 |                                         0
        8192 |                                         0
       16384 |                                         0
       32768 |                                         0
       65536 |@@@@@@                                   1526
      131072 |                                         0
```

It seems that the pwrite() function respects the new page size setup, but the write() function doesn't.

I traced the syscalls during a simple ""create database"", trying to investigate the JVM at the same time:

zfs pwrite /zones/orientdbZone/root/opt/orientdb-community-1.6.4/databases

```
       value  ------------- Distribution ------------- count
           0 |                                         0
           1 |@@@@                                     26
           2 |                                         0
           4 |                                         0
           8 |@@@@@@@                                  39
          16 |                                         0
          32 |                                         0
          64 |                                         0
         128 |                                         0
         256 |@@                                       13
         512 |                                         0
        1024 |                                         0
        2048 |                                         0
        4096 |                                         0
        8192 |                                         0
       16384 |                                         0
       32768 |@@@@@@@@@@@@@@@@@@@@@@@@@@@              160
       65536 |                                         0
```

 zfs write /zones/orientdbZone/root/opt/orientdb-community-1.6.4/databases

```
       value  ------------- Distribution ------------- count
           0 |                                         0
           1 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@         460
           2 |                                         0
           4 |                                         0
           8 |                                         4
          16 |@                                        18
          32 |                                         3
          64 |                                         0
         128 |                                         0
         256 |                                         0
         512 |                                         0
        1024 |                                         0
        2048 |                                         0
        4096 |                                         0
        8192 |                                         0
       16384 |                                         0
       32768 |                                         0
       65536 |@@@@@@                                   92
      131072 |                                         0
```

Here the JVM methods executed a suspicious number of times, during the ""create database"" process:

METHODS EXECUTED 460 TIMES (1 B)

java/io/RandomAccessFile.write0

METHODS EXECUTED 92 TIMES (64K)

com/orientechnologies/orient/core/db/ODatabaseWrapperAbstract.getName
com/orientechnologies/orient/core/storage/impl/local/paginated/wal/OWALPage.getFilledUpTo
 com/orientechnologies/orient/core/storage/impl/local/paginated/wal/OWriteAheadLog$LogSegment$FlushTask.flushPage
java/lang/StringBuffer.append
java/util/concurrent/ConcurrentLinkedQueue$Itr.next

METHODS EXECUTED 26 TIMES (1B)

com/orientechnologies/orient/core/storage/fs/OAbstractFile.<init>
com/orientechnologies/orient/core/storage/fs/OAbstractFile.create
com/orientechnologies/orient/core/storage/fs/OAbstractFile.lock
com/orientechnologies/orient/core/storage/fs/OAbstractFile.openChannel
com/orientechnologies/orient/core/storage/fs/OAbstractFile.setHeaderDirty
com/orientechnologies/orient/core/storage/fs/OFileClassic.<init>
com/orientechnologies/orient/core/storage/fs/OFileClassic.create
com/orientechnologies/orient/core/storage/fs/OFileClassic.getBuffer
com/orientechnologies/orient/core/storage/fs/OFileClassic.setFilledUpTo
com/orientechnologies/orient/core/storage/fs/OFileClassic.setSize
com/orientechnologies/orient/core/storage/fs/OFileClassic.setSoftlyClosed
com/orientechnologies/orient/core/storage/fs/OFileClassic.setVersion
com/orientechnologies/orient/core/storage/impl/local/paginated/OLocalPaginatedStorage.getMode

METHODS EXECUTED 39 TIMES (8B)

com/orientechnologies/orient/core/storage/fs/OFileClassic.getWriteBuffer

METHODS EXECUTED 13 TIMES (256B)

com/orientechnologies/orient/core/storage/fs/OFileClassic.writeInt
java/io/OutputStream.<init>
",https://github.com/orientechnologies/orientdb/issues/2121,0.0,3.0,0.4897959183673469,49
136,"Image building ignores failures in CNB build phases
Currently, when attempting to use the Maven plugin to build an image using Cloud Native Buildpacks (`spring-boot:build-image`) if one of the phases results in a failure, the plugin continues on rather than failing immediately.  As an example, specifying an invalid value for  `$BP_JAVA_VERSION` results in the build failing but some sort of image being exported:

```shell
 > Running builder
    [builder]     
    [builder]     Cloud Foundry OpenJDK Buildpack v1.0.80
    [builder]     
    [builder]     Cloud Foundry OpenJDK Buildpack v1.0.80
    [builder]       no valid dependencies for openjdk-jre, 13.0.2, and io.buildpacks.stacks.bionic in [(openjdk-jre, 8.0.232, [io.buildpacks.stacks.bionic org.cloudfoundry.stacks.cflinuxfs3]), (openjdk-jre, 11.0.5, [io.buildpacks.stacks.bionic org.cloudfoundry.stacks.cflinuxfs3]), (openjdk-jre, 13.0.1, [io.buildpacks.stacks.bionic org.cloudfoundry.stacks.cflinuxfs3]), (openjdk-jdk, 8.0.232, [io.buildpacks.stacks.bionic org.cloudfoundry.stacks.cflinuxfs3]), (openjdk-jdk, 11.0.5, [io.buildpacks.stacks.bionic org.cloudfoundry.stacks.cflinuxfs3]), (openjdk-jdk, 13.0.1, [io.buildpacks.stacks.bionic org.cloudfoundry.stacks.cflinuxfs3])]
    [builder]     ERROR: failed to build: exit status 102
 > Running exporter
    [exporter]    Adding layer 'app'
    [exporter]    Adding layer 'config'
    [exporter]    Reusing layer 'launcher'
    [exporter]    Reusing layer 'org.cloudfoundry.openjdk:openjdk-jre'
    [exporter]    Reusing layer 'org.cloudfoundry.jvmapplication:executable-jar'
    [exporter]    Reusing layer 'org.cloudfoundry.springboot:spring-boot'
    [exporter]    Reusing layer 'org.cloudfoundry.springautoreconfiguration:auto-reconfiguration'
    [exporter]    ERROR: failed to export: read build metadata: open /layers/config/metadata.toml: no such file or directory
 > Running cacher
    [cacher]      Reusing layer 'org.cloudfoundry.openjdk:2f08c469c9a8adea1b6ee3444ba2a8242a7e99d87976a077faf037a9eb7f884b'
    [cacher]      Reusing layer 'org.cloudfoundry.jvmapplication:executable-jar'
    [cacher]      Reusing layer 'org.cloudfoundry.springboot:spring-boot'
    [cacher]      Reusing layer 'org.cloudfoundry.springautoreconfiguration:46ab131165317d91fd4ad3186abf755222744e2d277dc413def06f3ad45ab150'
Successfully built image 'docker.io/library/build-image-test:0.0.1-SNAPSHOT'
```

The same failure simulated on `pack` results in the following:

```shell
$ pack build applications/jar --path applications/jar --builder cloudfoundry/cnb:bionic --env BP_JAVA_VERSION=""13.0.1""
bionic: Pulling from cloudfoundry/cnb
Digest: sha256:efe9b17ac151ab53d8eaa1149d0fd44357f9cd0842a7bfb5a2894c02ae143ab7
Status: Image is up to date for cloudfoundry/cnb:bionic
base-cnb: Pulling from cloudfoundry/run
Digest: sha256:ba9998ae4bb32ab43a7966c537aa1be153092ab0c7536eeef63bcd6336cbd0db
Status: Image is up to date for cloudfoundry/run:base-cnb
===> DETECTING
[detector] 6 of 13 buildpacks participating
[detector] org.cloudfoundry.openjdk                   v1.1.8
[detector] org.cloudfoundry.jvmapplication            v1.0.136
[detector] org.cloudfoundry.tomcat                    v1.1.102
[detector] org.cloudfoundry.springboot                v1.1.2
[detector] org.cloudfoundry.distzip                   v1.0.171
[detector] org.cloudfoundry.springautoreconfiguration v1.0.187
===> ANALYZING
[analyzer] Restoring metadata for ""org.cloudfoundry.openjdk:java-security-properties"" from app image
[analyzer] Restoring metadata for ""org.cloudfoundry.openjdk:jvmkill"" from app image
[analyzer] Restoring metadata for ""org.cloudfoundry.openjdk:link-local-dns"" from app image
[analyzer] Restoring metadata for ""org.cloudfoundry.openjdk:memory-calculator"" from app image
[analyzer] Restoring metadata for ""org.cloudfoundry.openjdk:openjdk-jre"" from app image
[analyzer] Restoring metadata for ""org.cloudfoundry.openjdk:security-provider-configurer"" from app image
[analyzer] Restoring metadata for ""org.cloudfoundry.openjdk:class-counter"" from app image
[analyzer] Restoring metadata for ""org.cloudfoundry.openjdk:a3092627b082cb3cdbbe4b255d35687126aa604e6b613dcda33be9f7e1277162"" from cache
[analyzer] Restoring metadata for ""org.cloudfoundry.openjdk:897f16fe8e056395209e35d2384013bd1ff250e717465769079e3f4793628c34"" from cache
[analyzer] Restoring metadata for ""org.cloudfoundry.openjdk:90d40eab6959a7b4059c6409c4505040e8a04f75a481f7282e53430df3edda3e"" from cache
===> RESTORING
[restorer] Restoring data for ""org.cloudfoundry.openjdk:897f16fe8e056395209e35d2384013bd1ff250e717465769079e3f4793628c34"" from cache
[restorer] Restoring data for ""org.cloudfoundry.openjdk:90d40eab6959a7b4059c6409c4505040e8a04f75a481f7282e53430df3edda3e"" from cache
[restorer] Restoring data for ""org.cloudfoundry.openjdk:a3092627b082cb3cdbbe4b255d35687126aa604e6b613dcda33be9f7e1277162"" from cache
===> BUILDING
[builder] 
[builder] Cloud Foundry OpenJDK Buildpack v1.1.8
[builder] 
[builder] Cloud Foundry OpenJDK Buildpack v1.1.8
[builder]   no valid dependencies for openjdk-jre, 13.0.1, and io.buildpacks.stacks.bionic in [(openjdk-jre, 8.0.242, [io.buildpacks.stacks.bionic org.cloudfoundry.stacks.cflinuxfs3]), (openjdk-jre, 11.0.6, [io.buildpacks.stacks.bionic org.cloudfoundry.stacks.cflinuxfs3]), (openjdk-jre, 13.0.2, [io.buildpacks.stacks.bionic org.cloudfoundry.stacks.cflinuxfs3]), (openjdk-jdk, 8.0.242, [io.buildpacks.stacks.bionic org.cloudfoundry.stacks.cflinuxfs3]), (openjdk-jdk, 11.0.6, [io.buildpacks.stacks.bionic org.cloudfoundry.stacks.cflinuxfs3]), (openjdk-jdk, 13.0.2, [io.buildpacks.stacks.bionic org.cloudfoundry.stacks.cflinuxfs3]), (jvmkill, 1.16.0, [io.buildpacks.stacks.bionic org.cloudfoundry.stacks.cflinuxfs3]), (memory-calculator, 4.0.0, [io.buildpacks.stacks.bionic org.cloudfoundry.stacks.cflinuxfs3])]
[builder] ERROR: failed to build: exit status 102
ERROR: failed with status code: 7
```

Any failure state generated by the lifecycle should cause failure of the build of the image.",https://github.com/spring-projects/spring-boot/issues/19949,0.0,3.0,2.0,91
218,"NullPointerException in AbstractRecord.getLockCount
We found the following exception in our cluster logs this morning. This looks to be a concurrency edge case - getLockCount is relying on a volatile variable being non-null.

This was found on Hazelcast 2.1 with the Sun JDK 1.6.0_31 i386 on CentOS 5.8 x86_64.

```
java.lang.NullPointerException
    at com.hazelcast.impl.AbstractRecord.getLockCount(AbstractRecord.java:417)
    at com.hazelcast.impl.AbstractRecord.isEvictable(AbstractRecord.java:153)
    at com.hazelcast.impl.CMap.startCleanup(CMap.java:1332)
    at com.hazelcast.impl.ConcurrentMapManager$4.run(ConcurrentMapManager.java:431)
    at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
    at java.lang.Thread.run(Thread.java:662)
```
",https://github.com/hazelcast/hazelcast/issues/166,0.0,3.0,0.0,196
369,"`javax.websocket.server.ServerContainer` is missing from ServletContext for pure SpringBoot application
`javax.websocket.server.ServerContainer` from ServletContext is `null` when SpringBoot is used (without Spring WebSocket).  Spring WebSocket shoudn't be required to support it as underlying Tomcat(or Jetty) does exposed it like the Servlet Specification is required. More info [here](https://github.com/Atmosphere/atmosphere/issues/1836), sample [here](https://github.com/henri-tremblay/hipster-atmosphere)
",https://github.com/spring-projects/spring-boot/issues/2341,0.0,3.0,2.0,91
42,"Changes object type of the previous value in StringRepeatCountEncodingStrategy
#### Description
Current previous value is stored as a String, if input value is [null, null, ""value"", ""value""], it is impossible to distinguish between the initial value and the previous value.
To save the previous value, change it to AtomicReference.
",https://github.com/naver/pinpoint/issues/3369,0.0,0.0,2.982142857142857,112
108,"FilePart file not properly closed on UnknownHostException
Running Java command line application on machine with the following specs:

Windows 7 Professional - 64 bit
Service Pack 1
32 GB RAM
Java Version 1.8.0_91
Java SE Runtime Environment (build 1.8.0_91-b15)
Java HotSpot 64-bit Server VM (build 25.91-b15, mixed mode)

If synchronous execute() method called and UnknownHostException thrown, FilePart file is not closed and a subsequent ATOMIC_MOVE call fails with error: 'The process cannot access the file because it is being used by another process.'

```
    // code snippet with sensitive portions removed
    void transmit(final File file) {
        try {
            String authorization = """";

           ** stuff here to get authorization code

            BoundRequestBuilder request = client.preparePost(String.format(""%s/api/files/save"", url))
                    .addHeader(""Authorization"", authorization)
                    .addHeader(""Content-Type"", ""multipart/form-data"")
                    .addBodyPart(new StringPart(""transferId"", UUID.randomUUID().toString()))
                    .addBodyPart(new StringPart(""timestamp"", Timestamp.from(Instant.now()).toString()))
                    .addBodyPart(new FilePart(""file"", file, ""text/plain""));

            Response response = request.execute().get();
            if ( response != null ) {
                 // do stuff with response here
            }
        } catch ( Exception ex ) {
           // code to copy file to a different folder fails here
           // Reason: The process cannot access the file because it is being used by another process.
           // using the following code to move the file
           Files.move(<source path>, <dest path>, ATOMIC_MOVE);
        }
    }

```",https://github.com/AsyncHttpClient/async-http-client/issues/1418,0.0,1.0,0.6026785714285714,224
375,"database cursor not closed in certain scenarios
Bug reported on oC tracker, also valid for Nc:

---
### Actual behaviour

-database cursor may be left open
### Expected behaviour

-cursors even empty ones (moveToFirst returns false) should be closed

The database cursor used by the delete() method (Line 94) in FileContentProvider class may be left unclosed if cursor.moveToFirst() returns false:

https://github.com/owncloud/android/blob/master/src/com/owncloud/android/providers/FileContentProvider.java

```
if (c != null && c.moveToFirst()) {
                    remoteId = c.getString(c.getColumnIndex(ProviderTableMeta.FILE_REMOTE_ID));
                    //ThumbnailsCacheManager.removeFileFromCache(remoteId);
                    c.close();
                }
```

---

I'll open a PR right away.
",https://github.com/nextcloud/android/issues/305,0.0,1.0,3.0,28
382,"ignore_missing removed from _aliases
Continuing discussion from:
https://github.com/elasticsearch/elasticsearch/pull/7234#issuecomment-55948380

It appears that the recent Get Indices API removes ignore_missing:

Elasticsearch 1.3.2

```
curl -XGET  http://localhost:9200/logstash-2014.09.16,logstash-2014.09.17/_aliases?ignore_missing=true;echo
{""logstash-2014.09.16"":{""aliases"":{}}}
```

Elasticsearch 1.4 branch

```
$ curl -XGET  http://localhost:9200/logstash-2014.09.16,logstash-2014.09.17/_aliases?ignore_missing=true;echo
{""error"":""IndexMissingException[[logstash-2014.09.17] missing]"",""status"":404}
```

Technically ignore_missing was slated for removal in Elasticsearch 1.0 (http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/_parameters.html#_parameters), however it was not removed from this API, meaning this this will introduce a breaking change for 1.4. 

It might be better to deprecate ignore_missing and remove it in Elasticsearch 2.0.
",https://github.com/elastic/elasticsearch/issues/7793,0.0,3.0,2.0,546
383,"java.lang.VerifyError: com/facebook/i/k at SoLoader.initImpl$230dc011(SoLoader.java:203)
### Description

Crash is happening on Android 4.x devices, when APK is built with ProGuard enabled and 'proguard-android-optimize.txt' configuration file.

### Reproduction

1. Get an Android 4.x device
2. Build an app with following build settings (""-optimize"" is the important part):
```
debug {
    minifyEnabled true
    proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro', 'proguard-fresco.pro'
}
```
3. BOOM!

You can find all the detailed information and system dumps here: http://crashes.to/s/c450feed2e9

### Additional Information

* Fresco version: 1.8.0
* Platform version: Android 4.x.",https://github.com/facebook/fresco/issues/2039,0.0,2.0,3.0,14
120,"Forking cannot be disabled if Spring Loaded is present
After change https://github.com/spring-projects/spring-boot/commit/f4fbc3e33955c34aae21e93d8b235d9914213080 the new logic disrespects configuration option `fork=false` if hotswap classloader (springloaded) present.
",https://github.com/spring-projects/spring-boot/issues/2220,0.0,3.0,2.0,91
387,"multithreaded http2 GET occasionally hang
When running multithreaded HTTP2 GET requests against nginx server, okhttp 3.8.1 occasionally hangs with all client threads stuck with the stacktrace like the one below and no `Http2Connection$ReaderRunnable` thread running. This is on OSX using Oracle java 1.8.0_131 jdk, if this makes any difference.

The problem may be related to server [limiting the number of requests using the same connection to 1000](http://nginx.org/en/docs/http/ngx_http_v2_module.html#http2_max_requests), then sending `GOAWAY` frame. But I am not sure how to setup a standalone test for this hypothesis and generally out of ideas how to troubleshoot this further.


```
""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fdc1f9bd800 nid=0x8603 in Object.wait() [0x0000700002c18000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at okhttp3.internal.http2.Http2Stream.waitForIo(Http2Stream.java:577)
	at okhttp3.internal.http2.Http2Stream.takeResponseHeaders(Http2Stream.java:143)
	- locked <0x00000003c109ef90> (a okhttp3.internal.http2.Http2Stream)
	at okhttp3.internal.http2.Http2Codec.readResponseHeaders(Http2Codec.java:120)
	at okhttp3.internal.http.CallServerInterceptor.intercept(CallServerInterceptor.java:75)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92)
	at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:45)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67)
	at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:93)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67)
	at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92)
	at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:120)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67)
	at okhttp3.logging.HttpLoggingInterceptor.intercept(HttpLoggingInterceptor.java:211)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67)
	at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:185)
	at okhttp3.RealCall.execute(RealCall.java:69)
	at io.takari.generation.aether.connector.OkhttpContentLoader.get(OkhttpContentLoader.java:105)
...
```",https://github.com/square/okhttp/issues/3422,0.0,3.0,0.05194805194805195,77
392,"org.exist.security.realm.openid.OpenIDUtility never releases READ_LOCK
READ_LOCK is acquired here: https://github.com/eXist-db/exist/blob/develop/extensions/security/openid/src/org/exist/security/realm/openid/OpenIDUtility.java#L107",https://github.com/eXist-db/exist/issues/1415,0.0,0.0,2.0,28
177,"Map.clear() causes corruption of Database.
If you run the test below TWICE on mapdb-1.0.6 it throws a nasty Exception on the second run. If it is run a third time, it gets worse.
If the clear() method is removed, then it can be run as many times as one wants.

```
@Test
public void testCorruption()
    throws Exception
{
    final int INSTANCES = 100000;
    File applicationDbFile = new File( databaseDir, ""testing"" );
    DBMaker maker = DBMaker.newFileDB( applicationDbFile );
    TxMaker txMaker = maker.makeTxMaker();
    DB tx = txMaker.makeTx();
    byte[] data = new byte[128];
    try
    {
        ConcurrentMap<Long, byte[]> map = tx.getHashMap( ""persons"" );
        map.clear();
        for( int i = 0; i < INSTANCES; i++ )
        {
            map.put( (long) i, data );
        }
        tx.commit();
    }
    catch( RuntimeException ex )
    {
        tx.rollback();
        throw ex;
    }
    finally
    {
        tx.close();
    }
}
```

And the Excepiton is;

```
java.lang.AssertionError: unknown trans log instruction '0' at log offset: 5111834
    at org.mapdb.StoreWAL.replayLogFile(StoreWAL.java:858)
    at org.mapdb.StoreWAL.commit(StoreWAL.java:637)
    at org.mapdb.EngineWrapper.commit(EngineWrapper.java:94)
    at org.mapdb.EngineWrapper.commit(EngineWrapper.java:94)
    at org.mapdb.TxEngine.superCommit(TxEngine.java:310)
    at org.mapdb.TxEngine$Tx.commit(TxEngine.java:558)
    at org.mapdb.EngineWrapper.commit(EngineWrapper.java:94)
    at org.mapdb.TxEngine.commit(TxEngine.java:287)
    at org.mapdb.DB.commit(DB.java:1595)
    at org.mapdb.CorruptionTest.testCorruption(CorruptionTest.java:50)
```
",https://github.com/jankotek/mapdb/issues/381,0.0,1.0,0.17142857142857143,70
206,"NPE in correction proposals
Not quite #1708 

```
java.lang.NullPointerException
    at com.redhat.ceylon.eclipse.code.correct.ChangeDeclarationProposal.addChangeDeclarationProposal(ChangeDeclarationProposal.java:32)
    at com.redhat.ceylon.eclipse.code.correct.CeylonCorrectionProcessor.addProposals(CeylonCorrectionProcessor.java:738)
    at com.redhat.ceylon.eclipse.code.correct.CeylonCorrectionProcessor.collectCorrections(CeylonCorrectionProcessor.java:517)
    at com.redhat.ceylon.eclipse.code.hover.AnnotationInfo.collectProposals(AnnotationInfo.java:143)
    at com.redhat.ceylon.eclipse.code.hover.AnnotationInfo.getCompletionProposals(AnnotationInfo.java:96)
    at com.redhat.ceylon.eclipse.code.hover.AnnotationInformationControl$2.run(AnnotationInformationControl.java:256)
    at org.eclipse.core.internal.jobs.Worker.run(Worker.java:55)
```
",https://github.com/eclipse/ceylon-ide-eclipse/issues/1711,0.0,3.0,0.0,49
